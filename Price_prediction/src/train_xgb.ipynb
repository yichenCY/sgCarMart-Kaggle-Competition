{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be3c924-8ad9-43e8-a24d-cf9fde869df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "test = pd.read_pickle('test_add_cate.pkl')\n",
    "train = pd.read_pickle('train_add_cate.pkl')\n",
    "label = train['price']\n",
    "train = train.drop(['price'],axis=1)\n",
    "# train = train.drop(['listing_id','make_model_combined','svd9_category','suggested_price','price'],axis=1)\n",
    "# test = test.drop(['listing_id','make_model_combined','suggested_price','svd9_category'],axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train,label,test_size=0.0002,random_state=111)\n",
    "drop_list = ['vintage cars',\n",
    " 'coe car',\n",
    " 'consignment car',\n",
    " 'sta evaluated car',\n",
    " 'sgcarmart warranty cars',\n",
    " 'low mileage car',\n",
    " 'electric cars',\n",
    " 'direct owner sale',\n",
    " 'parf car',\n",
    " 'opc car',\n",
    " 'premium ad car',\n",
    " 'hybrid cars',\n",
    " 'imported used vehicle',\n",
    " 'almost new car',\n",
    " 'rare & exotic']\n",
    "X_train,y_train = train,label\n",
    "X_train.drop(drop_list,axis=1)\n",
    "data_train = xgb.DMatrix(X_train.fillna(-1), label=y_train)\n",
    "data_test = xgb.DMatrix(X_test.fillna(-1), label=y_test)\n",
    "data_rmse_test = xgb.DMatrix(X_test.fillna(-1))\n",
    "test_DMatrix = xgb.DMatrix(test.fillna(-1))\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de550fb3-d7c7-44f5-8c5f-6ac7bb95d85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 11, 'eta': 0.01, 'silent': 1, 'gamma': 0, 'objective': 'reg:linear', 'reg_alpha': 1, 'reg_lambda': 1, 'n_estimators': 300, 'subsample': 0.9, 'colsample_bytree': 0.6, 'min_child_weight': 3}\n",
      "[02:16:55] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[02:16:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\teval-rmse:99767.09375\ttrain-rmse:173784.85938\n",
      "[1]\teval-rmse:98744.17969\ttrain-rmse:172182.60938\n",
      "[2]\teval-rmse:97750.98438\ttrain-rmse:170591.42188\n",
      "[3]\teval-rmse:96739.70312\ttrain-rmse:169052.07812\n",
      "[4]\teval-rmse:95730.85156\ttrain-rmse:167466.76562\n",
      "[5]\teval-rmse:94616.89844\ttrain-rmse:165917.62500\n",
      "[6]\teval-rmse:93553.35938\ttrain-rmse:164408.10938\n",
      "[7]\teval-rmse:92640.61719\ttrain-rmse:162880.57812\n",
      "[8]\teval-rmse:91665.68750\ttrain-rmse:161369.81250\n",
      "[9]\teval-rmse:90724.41406\ttrain-rmse:159860.43750\n",
      "[10]\teval-rmse:89803.72656\ttrain-rmse:158406.32812\n",
      "[11]\teval-rmse:88886.53125\ttrain-rmse:156948.17188\n",
      "[12]\teval-rmse:87982.41406\ttrain-rmse:155490.03125\n",
      "[13]\teval-rmse:87050.99219\ttrain-rmse:154057.76562\n",
      "[14]\teval-rmse:86133.82031\ttrain-rmse:152625.20312\n",
      "[15]\teval-rmse:85266.78906\ttrain-rmse:151291.29688\n",
      "[16]\teval-rmse:84406.00781\ttrain-rmse:149905.56250\n",
      "[17]\teval-rmse:83524.69531\ttrain-rmse:148529.87500\n",
      "[18]\teval-rmse:82650.79688\ttrain-rmse:147147.46875\n",
      "[19]\teval-rmse:81665.82812\ttrain-rmse:145795.14062\n",
      "[20]\teval-rmse:80842.60156\ttrain-rmse:144455.28125\n",
      "[21]\teval-rmse:79943.69531\ttrain-rmse:143147.34375\n",
      "[22]\teval-rmse:79154.62500\ttrain-rmse:141822.75000\n",
      "[23]\teval-rmse:78278.45312\ttrain-rmse:140518.54688\n",
      "[24]\teval-rmse:77483.14062\ttrain-rmse:139214.21875\n",
      "[25]\teval-rmse:76705.00781\ttrain-rmse:137945.46875\n",
      "[26]\teval-rmse:75920.15625\ttrain-rmse:136660.35938\n",
      "[27]\teval-rmse:75213.33594\ttrain-rmse:135389.48438\n",
      "[28]\teval-rmse:74472.59375\ttrain-rmse:134143.04688\n",
      "[29]\teval-rmse:73675.91406\ttrain-rmse:132925.60938\n",
      "[30]\teval-rmse:72772.90625\ttrain-rmse:131705.95312\n",
      "[31]\teval-rmse:71960.54688\ttrain-rmse:130520.60156\n",
      "[32]\teval-rmse:71277.16406\ttrain-rmse:129322.78125\n",
      "[33]\teval-rmse:70555.35938\ttrain-rmse:128119.92969\n",
      "[34]\teval-rmse:69715.83594\ttrain-rmse:126950.23438\n",
      "[35]\teval-rmse:68973.77344\ttrain-rmse:125777.14844\n",
      "[36]\teval-rmse:68257.34375\ttrain-rmse:124619.42969\n",
      "[37]\teval-rmse:67501.02344\ttrain-rmse:123475.50781\n",
      "[38]\teval-rmse:66841.33594\ttrain-rmse:122334.69531\n",
      "[39]\teval-rmse:66048.50781\ttrain-rmse:121229.51562\n",
      "[40]\teval-rmse:65233.78516\ttrain-rmse:120124.10938\n",
      "[41]\teval-rmse:64665.76953\ttrain-rmse:119080.91406\n",
      "[42]\teval-rmse:63988.97266\ttrain-rmse:117982.85156\n",
      "[43]\teval-rmse:63388.11328\ttrain-rmse:116923.35938\n",
      "[44]\teval-rmse:62794.91406\ttrain-rmse:115868.47656\n",
      "[45]\teval-rmse:62120.48438\ttrain-rmse:114822.46094\n",
      "[46]\teval-rmse:61466.15234\ttrain-rmse:113773.12500\n",
      "[47]\teval-rmse:60699.85938\ttrain-rmse:112731.46094\n",
      "[48]\teval-rmse:60061.19922\ttrain-rmse:111693.75000\n",
      "[49]\teval-rmse:59374.71094\ttrain-rmse:110681.85938\n",
      "[50]\teval-rmse:58719.53516\ttrain-rmse:109667.60156\n",
      "[51]\teval-rmse:58081.50000\ttrain-rmse:108674.96094\n",
      "[52]\teval-rmse:57447.82812\ttrain-rmse:107676.49219\n",
      "[53]\teval-rmse:56748.80078\ttrain-rmse:106699.01562\n",
      "[54]\teval-rmse:56068.54688\ttrain-rmse:105728.81250\n",
      "[55]\teval-rmse:55398.11719\ttrain-rmse:104775.41406\n",
      "[56]\teval-rmse:54749.61719\ttrain-rmse:103823.45312\n",
      "[57]\teval-rmse:54191.12500\ttrain-rmse:102881.28125\n",
      "[58]\teval-rmse:53553.42188\ttrain-rmse:101958.57031\n",
      "[59]\teval-rmse:53026.47656\ttrain-rmse:101025.21875\n",
      "[60]\teval-rmse:52369.20312\ttrain-rmse:100122.97656\n",
      "[61]\teval-rmse:51763.17188\ttrain-rmse:99228.92188\n",
      "[62]\teval-rmse:51133.78516\ttrain-rmse:98333.77344\n",
      "[63]\teval-rmse:50485.81250\ttrain-rmse:97448.88281\n",
      "[64]\teval-rmse:49928.51172\ttrain-rmse:96573.48438\n",
      "[65]\teval-rmse:49371.85547\ttrain-rmse:95713.29688\n",
      "[66]\teval-rmse:48765.53125\ttrain-rmse:94856.35938\n",
      "[67]\teval-rmse:48276.36719\ttrain-rmse:94002.91406\n",
      "[68]\teval-rmse:47664.70703\ttrain-rmse:93157.31250\n",
      "[69]\teval-rmse:47236.53516\ttrain-rmse:92346.37500\n",
      "[70]\teval-rmse:46768.27734\ttrain-rmse:91507.75000\n",
      "[71]\teval-rmse:46253.46484\ttrain-rmse:90693.45312\n",
      "[72]\teval-rmse:45674.00391\ttrain-rmse:89879.15625\n",
      "[73]\teval-rmse:45173.96484\ttrain-rmse:89070.56250\n",
      "[74]\teval-rmse:44683.64453\ttrain-rmse:88266.14844\n",
      "[75]\teval-rmse:44157.08984\ttrain-rmse:87472.42969\n",
      "[76]\teval-rmse:43647.80078\ttrain-rmse:86702.31250\n",
      "[77]\teval-rmse:43110.23438\ttrain-rmse:85936.28906\n",
      "[78]\teval-rmse:42553.71875\ttrain-rmse:85175.67969\n",
      "[79]\teval-rmse:42121.56641\ttrain-rmse:84421.25000\n",
      "[80]\teval-rmse:41618.98047\ttrain-rmse:83682.21875\n",
      "[81]\teval-rmse:41089.47656\ttrain-rmse:82951.83594\n",
      "[82]\teval-rmse:40574.28516\ttrain-rmse:82207.42969\n",
      "[83]\teval-rmse:40070.98047\ttrain-rmse:81466.96094\n",
      "[84]\teval-rmse:39650.33984\ttrain-rmse:80739.66406\n",
      "[85]\teval-rmse:39149.01562\ttrain-rmse:80036.85156\n",
      "[86]\teval-rmse:38706.83984\ttrain-rmse:79328.43750\n",
      "[87]\teval-rmse:38202.22266\ttrain-rmse:78630.14062\n",
      "[88]\teval-rmse:37779.52344\ttrain-rmse:77926.84375\n",
      "[89]\teval-rmse:37353.73438\ttrain-rmse:77228.45312\n",
      "[90]\teval-rmse:36932.55078\ttrain-rmse:76546.50781\n",
      "[91]\teval-rmse:36500.05469\ttrain-rmse:75870.60156\n",
      "[92]\teval-rmse:36013.54688\ttrain-rmse:75197.33594\n",
      "[93]\teval-rmse:35647.98438\ttrain-rmse:74530.00781\n",
      "[94]\teval-rmse:35300.19141\ttrain-rmse:73864.11719\n",
      "[95]\teval-rmse:34851.80078\ttrain-rmse:73206.43750\n",
      "[96]\teval-rmse:34511.78516\ttrain-rmse:72569.32031\n",
      "[97]\teval-rmse:34083.19531\ttrain-rmse:71943.80469\n",
      "[98]\teval-rmse:33725.67969\ttrain-rmse:71308.56250\n",
      "[99]\teval-rmse:33336.99609\ttrain-rmse:70681.75000\n",
      "[100]\teval-rmse:32896.48438\ttrain-rmse:70081.39844\n",
      "[101]\teval-rmse:32478.58594\ttrain-rmse:69463.88281\n",
      "[102]\teval-rmse:32077.43359\ttrain-rmse:68852.71875\n",
      "[103]\teval-rmse:31716.64062\ttrain-rmse:68238.08594\n",
      "[104]\teval-rmse:31315.88086\ttrain-rmse:67649.16406\n",
      "[105]\teval-rmse:30932.77148\ttrain-rmse:67059.97656\n",
      "[106]\teval-rmse:30535.73242\ttrain-rmse:66468.86719\n",
      "[107]\teval-rmse:30231.67969\ttrain-rmse:65882.31250\n",
      "[108]\teval-rmse:29877.80273\ttrain-rmse:65309.38281\n",
      "[109]\teval-rmse:29524.52148\ttrain-rmse:64729.67578\n",
      "[110]\teval-rmse:29160.46875\ttrain-rmse:64178.40625\n",
      "[111]\teval-rmse:28833.66211\ttrain-rmse:63625.18750\n",
      "[112]\teval-rmse:28493.79688\ttrain-rmse:63076.74609\n",
      "[113]\teval-rmse:28160.62500\ttrain-rmse:62520.12891\n",
      "[114]\teval-rmse:27808.59570\ttrain-rmse:61973.75781\n",
      "[115]\teval-rmse:27493.03125\ttrain-rmse:61433.37109\n",
      "[116]\teval-rmse:27206.38086\ttrain-rmse:60891.64844\n",
      "[117]\teval-rmse:26837.67773\ttrain-rmse:60371.41406\n",
      "[118]\teval-rmse:26549.95898\ttrain-rmse:59861.27734\n",
      "[119]\teval-rmse:26276.79688\ttrain-rmse:59336.94922\n",
      "[120]\teval-rmse:25995.71094\ttrain-rmse:58825.94141\n",
      "[121]\teval-rmse:25699.67969\ttrain-rmse:58322.29688\n",
      "[122]\teval-rmse:25397.58203\ttrain-rmse:57825.77344\n",
      "[123]\teval-rmse:25132.28320\ttrain-rmse:57314.59766\n",
      "[124]\teval-rmse:24781.98438\ttrain-rmse:56829.72656\n",
      "[125]\teval-rmse:24467.22852\ttrain-rmse:56346.51953\n",
      "[126]\teval-rmse:24198.73242\ttrain-rmse:55849.67188\n",
      "[127]\teval-rmse:23941.78711\ttrain-rmse:55373.37891\n",
      "[128]\teval-rmse:23633.99219\ttrain-rmse:54901.49609\n",
      "[129]\teval-rmse:23373.87305\ttrain-rmse:54428.22656\n",
      "[130]\teval-rmse:23037.53516\ttrain-rmse:53977.21484\n",
      "[131]\teval-rmse:22783.44336\ttrain-rmse:53527.87891\n",
      "[132]\teval-rmse:22506.36719\ttrain-rmse:53068.98438\n",
      "[133]\teval-rmse:22247.14453\ttrain-rmse:52608.37891\n",
      "[134]\teval-rmse:22018.39648\ttrain-rmse:52151.14844\n",
      "[135]\teval-rmse:21712.20508\ttrain-rmse:51717.96484\n",
      "[136]\teval-rmse:21477.42773\ttrain-rmse:51282.90625\n",
      "[137]\teval-rmse:21182.85352\ttrain-rmse:50846.63672\n",
      "[138]\teval-rmse:20868.23438\ttrain-rmse:50421.36328\n",
      "[139]\teval-rmse:20594.04297\ttrain-rmse:49997.41016\n",
      "[140]\teval-rmse:20315.69727\ttrain-rmse:49583.53906\n",
      "[141]\teval-rmse:20091.42188\ttrain-rmse:49169.34766\n",
      "[142]\teval-rmse:19876.99219\ttrain-rmse:48735.74219\n",
      "[143]\teval-rmse:19627.06641\ttrain-rmse:48335.00781\n",
      "[144]\teval-rmse:19385.97461\ttrain-rmse:47923.95703\n",
      "[145]\teval-rmse:19156.89844\ttrain-rmse:47527.03516\n",
      "[146]\teval-rmse:18883.19141\ttrain-rmse:47126.78516\n",
      "[147]\teval-rmse:18712.08984\ttrain-rmse:46734.76172\n",
      "[148]\teval-rmse:18462.71289\ttrain-rmse:46351.86328\n",
      "[149]\teval-rmse:18205.51172\ttrain-rmse:45986.12109\n",
      "[150]\teval-rmse:17985.15039\ttrain-rmse:45591.84375\n",
      "[151]\teval-rmse:17782.07031\ttrain-rmse:45197.52344\n",
      "[152]\teval-rmse:17547.24414\ttrain-rmse:44832.10547\n",
      "[153]\teval-rmse:17352.02148\ttrain-rmse:44470.33203\n",
      "[154]\teval-rmse:17151.62500\ttrain-rmse:44093.25781\n",
      "[155]\teval-rmse:16906.60938\ttrain-rmse:43731.38281\n",
      "[156]\teval-rmse:16716.75195\ttrain-rmse:43351.76172\n",
      "[157]\teval-rmse:16544.10547\ttrain-rmse:42992.65625\n",
      "[158]\teval-rmse:16310.95996\ttrain-rmse:42638.31641\n",
      "[159]\teval-rmse:16111.96484\ttrain-rmse:42286.14453\n",
      "[160]\teval-rmse:15916.95508\ttrain-rmse:41939.96484\n",
      "[161]\teval-rmse:15683.47168\ttrain-rmse:41591.61328\n",
      "[162]\teval-rmse:15478.35449\ttrain-rmse:41269.01953\n",
      "[163]\teval-rmse:15288.12598\ttrain-rmse:40920.25781\n",
      "[164]\teval-rmse:15070.03125\ttrain-rmse:40591.25781\n",
      "[165]\teval-rmse:14853.84082\ttrain-rmse:40254.64062\n",
      "[166]\teval-rmse:14670.10644\ttrain-rmse:39935.51953\n",
      "[167]\teval-rmse:14477.38184\ttrain-rmse:39597.73047\n",
      "[168]\teval-rmse:14249.98340\ttrain-rmse:39278.76172\n",
      "[169]\teval-rmse:14068.11133\ttrain-rmse:38944.93359\n",
      "[170]\teval-rmse:13865.46875\ttrain-rmse:38630.10547\n",
      "[171]\teval-rmse:13693.82324\ttrain-rmse:38302.27734\n",
      "[172]\teval-rmse:13488.16894\ttrain-rmse:38000.52734\n",
      "[173]\teval-rmse:13306.83594\ttrain-rmse:37693.34766\n",
      "[174]\teval-rmse:13113.66113\ttrain-rmse:37384.97266\n",
      "[175]\teval-rmse:12945.62891\ttrain-rmse:37081.16797\n",
      "[176]\teval-rmse:12765.65039\ttrain-rmse:36786.86328\n",
      "[177]\teval-rmse:12592.94238\ttrain-rmse:36495.80859\n",
      "[178]\teval-rmse:12384.88281\ttrain-rmse:36205.70312\n",
      "[179]\teval-rmse:12202.25391\ttrain-rmse:35930.74219\n",
      "[180]\teval-rmse:12038.26269\ttrain-rmse:35627.59375\n",
      "[181]\teval-rmse:11880.92676\ttrain-rmse:35331.70312\n",
      "[182]\teval-rmse:11721.41992\ttrain-rmse:35043.50781\n",
      "[183]\teval-rmse:11608.09473\ttrain-rmse:34771.16016\n",
      "[184]\teval-rmse:11486.37402\ttrain-rmse:34488.96094\n",
      "[185]\teval-rmse:11348.82617\ttrain-rmse:34204.85156\n",
      "[186]\teval-rmse:11192.38086\ttrain-rmse:33925.85938\n",
      "[187]\teval-rmse:11047.51953\ttrain-rmse:33669.66406\n",
      "[188]\teval-rmse:10890.71289\ttrain-rmse:33403.98828\n",
      "[189]\teval-rmse:10750.75488\ttrain-rmse:33129.09375\n",
      "[190]\teval-rmse:10631.54102\ttrain-rmse:32864.41406\n",
      "[191]\teval-rmse:10492.67090\ttrain-rmse:32597.90234\n",
      "[192]\teval-rmse:10373.00879\ttrain-rmse:32349.51953\n",
      "[193]\teval-rmse:10229.64062\ttrain-rmse:32085.78125\n",
      "[194]\teval-rmse:10089.54981\ttrain-rmse:31819.60352\n",
      "[195]\teval-rmse:9949.74316\ttrain-rmse:31566.49805\n",
      "[196]\teval-rmse:9789.20410\ttrain-rmse:31314.00000\n",
      "[197]\teval-rmse:9665.28516\ttrain-rmse:31055.63086\n",
      "[198]\teval-rmse:9573.51465\ttrain-rmse:30807.29297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-65795f80b723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         }\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_rmse_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m res = {\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param = {\n",
    "            'max_depth': 11, \n",
    "            'eta': 0.01, \n",
    "            'silent': 1, \n",
    "            'gamma':0,\n",
    "            'objective': 'reg:linear',\n",
    "            'reg_alpha':1,\n",
    "            'reg_lambda':1,\n",
    "            'n_estimators':300,\n",
    "#                 'num_boost_round':trial.suggest_int(\"num_boost_round\", 800, 3000),\n",
    "            'subsample':0.9,\n",
    "            'colsample_bytree':0.6,\n",
    "            'min_child_weight':3\n",
    "        }\n",
    "print(param)\n",
    "bst = xgb.train(param, data_train, num_boost_round=1500,evals=watch_list)\n",
    "rmse = np.sqrt(mean_squared_error(y_test.tolist(),list(bst.predict(data_rmse_test))))\n",
    "res = {\n",
    "\n",
    "            'Predicted':list(bst.predict(test_DMatrix))\n",
    "        }\n",
    "res=DataFrame(res)\n",
    "res.to_csv('model_saving3/xgboost_res_'+'final'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d86bd6-3263-4c58-9217-b90393b0c4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.7365299211906035,\n",
       "              learning_rate=0.06433836700594038, max_depth=18,\n",
       "              min_child_samples=30, min_child_weight=0.007499472789765832,\n",
       "              n_estimators=400, num_leaves=40, reg_alpha=0.3975937739726987,\n",
       "              reg_lambda=0.13116705819059657, subsample=0.9,\n",
       "              subsample_for_bin=50000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "hyper_params = {'colsample_bytree': 0.7365299211906035,\n",
    " 'learning_rate': 0.06433836700594038,\n",
    " 'max_depth': 18,\n",
    " 'min_child_samples': 30,\n",
    " 'min_child_weight': 0.007499472789765832,\n",
    " 'n_estimators': 400,\n",
    " 'num_leaves': 40,\n",
    " 'reg_alpha': 0.3975937739726987,\n",
    " 'reg_lambda': 0.13116705819059657,\n",
    " 'subsample': 0.9,\n",
    " 'subsample_for_bin': 50000}\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e6cc8-28c9-4466-837b-c61b6ce5e9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
